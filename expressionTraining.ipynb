# Install required libraries
!pip install numpy pandas tensorflow keras matplotlib pydot

# imports
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.utils import to_categorical
import datetime
import matplotlib.pyplot as plt

# classes
def prepare_data(dataframe, usage_type):
    """
    Prepare data for a specific usage type (Training, PublicTest, or PrivateTest)
    """
    df = dataframe[dataframe['Usage'] == usage_type]
    pixels = df['pixels'].tolist()
    width, height = 48, 48
    faces = []

    for pixel_sequence in pixels:
        face = [int(pixel) for pixel in pixel_sequence.split()]
        face = np.asarray(face).reshape(width, height)
        face = face.astype('float32')
        face /= 255.0
        faces.append(face)

    faces = np.asarray(faces)
    faces = np.expand_dims(faces, -1)  # Add channel dimension
    emotions = to_categorical(df['emotion'], num_classes=7)

    return faces, emotions

def load_fer2013():
    """
    Load and process the fer2013 dataset
    """
    print("Reading CSV file...")
    data = pd.read_csv('fer2013.csv')

    print("\nPreparing training data...")
    train_faces, train_emotions = prepare_data(data, 'Training')

    print("Preparing validation data...")
    val_faces, val_emotions = prepare_data(data, 'PublicTest')

    print("Preparing test data...")
    test_faces, test_emotions = prepare_data(data, 'PrivateTest')

    print("\nDataset shapes:")
    print("Training data shape:", train_faces.shape)
    print("Training labels shape:", train_emotions.shape)
    print("Validation data shape:", val_faces.shape)
    print("Validation labels shape:", val_emotions.shape)
    print("Test data shape:", test_faces.shape)
    print("Test labels shape:", test_emotions.shape)

    return train_faces, train_emotions, val_faces, val_emotions, test_faces, test_emotions

# Load the dataset
print("Loading dataset...")
X_train, y_train, X_val, y_val, X_test, y_test = load_fer2013()

# Define the model
def get_model(input_size, classes=7):
    model = tf.keras.models.Sequential()

    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_size))
    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(2, 2))
    model.add(Dropout(0.25))

    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))
    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Flatten())
    model.add(Dense(1024, activation='relu'))
    model.add(Dropout(0.5))

    model.add(Dense(classes, activation='softmax'))

    model.compile(optimizer=Adam(learning_rate=0.0001, decay=1e-6),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# Initialize model
row, col = 48, 48
classes = 7
model = get_model((row, col, 1), classes)
model.summary()

# Callbacks
chk_path = 'ferNet.h5'

checkpoint = ModelCheckpoint(filepath=chk_path,
                           save_best_only=True,
                           verbose=1,
                           mode='min',
                           monitor='val_loss')

earlystop = EarlyStopping(monitor='val_loss',
                         min_delta=0,
                         patience=3,
                         verbose=1,
                         restore_best_weights=True)

reduce_lr = ReduceLROnPlateau(monitor='val_loss',
                             factor=0.2,
                             patience=6,
                             verbose=1,
                             min_delta=0.0001)

csv_logger = CSVLogger('training.log')

callbacks = [checkpoint, reduce_lr, csv_logger, earlystop]

# Training the model
batch_size = 32
epochs = 30

print("X_train shape before model.fit:", X_train.shape)  # Should be (num_samples, 48, 48, 1)
print("y_train shape before model.fit:", y_train.shape)  # Should be (num_samples, 7)

hist = model.fit(X_train, y_train,
                validation_data=(X_val, y_val),
                epochs=epochs,
                batch_size=batch_size,
                callbacks=callbacks)

# Plotting the training and validation accuracy and loss
plt.figure(figsize=(14,5))

plt.subplot(1,2,2)
plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['train', 'validation'], loc='upper left')

plt.subplot(1,2,1)
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

# Evaluating the model
print("\nEvaluating on training data:")
train_loss, train_accu = model.evaluate(X_train, y_train)

print("\nEvaluating on validation data:")
val_loss, val_accu = model.evaluate(X_val, y_val)

print("\nEvaluating on test data:")
test_loss, test_accu = model.evaluate(X_test, y_test)

print("\nFinal Results:")
print("Training accuracy = {:.2f}%".format(train_accu*100))
print("Validation accuracy = {:.2f}%".format(val_accu*100))
print("Test accuracy = {:.2f}%".format(test_accu*100))

# Print emotion mapping for reference
emotion_map = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}
print("\nEmotion mapping:")
for key, value in emotion_map.items():
    print(f"{key}: {value}")

# Make predictions on the test data
predictions = model.predict(X_test)

# Convert predictions from probabilities to class labels
predicted_labels = np.argmax(predictions, axis=1)
true_labels = np.argmax(y_test, axis=1)

# Map the labels to emotion names using the emotion_map
predicted_emotions = [emotion_map[label] for label in predicted_labels]
true_emotions = [emotion_map[label] for label in true_labels]

# Create a DataFrame to store the results
results_df = pd.DataFrame({
    'True_Label': true_labels,
    'True_Emotion': true_emotions,
    'Predicted_Label': predicted_labels,
    'Predicted_Emotion': predicted_emotions
})

# Save the DataFrame to a CSV file
results_df.to_csv('test_predictions.csv', index=False)

print("Predictions saved to 'test_predictions.csv'")

# Save the Model
model.save("model.keras")
